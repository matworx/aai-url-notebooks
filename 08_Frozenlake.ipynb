{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises and code samples for the course Unsupervised and Reinforcement Learning (AAI-URL) in the Bachelor of AAI at Rosenheim University of Applied Sciences.\n",
    "\n",
    "# Frozenlake\n",
    "\n",
    "Documentation on frozen lake is here: https://www.gymlibrary.dev/environments/toy_text/frozen_lake/\n",
    "\n",
    "Frozen lake involves crossing a frozen lake from Start(S) to Goal(G) without falling into any Holes(H) by walking over the Frozen(F) lake. The agent may not always move in the intended direction due to the slippery nature of the frozen lake.\n",
    "\n",
    "1. Import relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a random _policy_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_policy(env):\n",
    "    \"\"\"Run a random policy for the given environment.\n",
    "    Logs the total reward and the number of steps until the terminal\n",
    "    state was reached.\n",
    "    Parameters\n",
    "    ----------\n",
    "    env: gym.envs.Environment\n",
    "      Instance of an OpenAI gym.\n",
    "    Returns\n",
    "    -------\n",
    "    (float, int)\n",
    "      First number is the total undiscounted reward received. The\n",
    "      second number is the total number of actions taken before the\n",
    "      episode finished.\n",
    "    \"\"\"\n",
    "    total_reward = 0\n",
    "    num_steps = 0\n",
    "    while True:\n",
    "        nextstate, reward, is_terminal, done, debug_info = env.step(env.action_space.sample())\n",
    "        print(env.render())\n",
    "        \n",
    "\n",
    "        total_reward += reward\n",
    "        num_steps += 1\n",
    "\n",
    "        if is_terminal:\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return total_reward, num_steps\n",
    "\n",
    "\n",
    "def print_env_info(env):\n",
    "    print('Environment has %s states and %s actions.' % (env.observation_space, env.action_space))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment has Discrete(16) states and Discrete(4) actions.\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "\n",
      "  (Up)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Agent received total reward of: 0.000000\n",
      "Agent took 9 steps\n"
     ]
    }
   ],
   "source": [
    "# create the environment\n",
    "env = gym.make('FrozenLake-v1', render_mode=\"ansi\", is_slippery= False)\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "print_env_info(env)\n",
    "\n",
    "total_reward, num_steps = run_random_policy(env)\n",
    "print('Agent received total reward of: %f' % total_reward)\n",
    "print('Agent took %d steps' % num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
