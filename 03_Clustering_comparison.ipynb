{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47423606",
   "metadata": {},
   "source": [
    "Exercises and code samples for the course Unsupervised and Reinforcement Learning (AAI-URL) in the Bachelor of AAI at Rosenheim University of Applied Sciences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc5fdb",
   "metadata": {},
   "source": [
    "# Comparing different clustering algorithms on toy datasets\n",
    "\n",
    "taken and simplified from https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py\n",
    "\n",
    "This example shows characteristics of different clustering algorithms on datasets that are “interesting” but still in 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56938fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgglomerativeClustering.__init__() got an unexpected keyword argument 'affinity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 127\u001b[0m\n\u001b[1;32m    125\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m.\u001b[39mKMeans(n_clusters\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    126\u001b[0m ward \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m.\u001b[39mAgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m], linkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m\"\u001b[39m, connectivity\u001b[38;5;241m=\u001b[39mconnectivity)\n\u001b[0;32m--> 127\u001b[0m average_linkage \u001b[38;5;241m=\u001b[39m \u001b[43mcluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAgglomerativeClustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinkage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffinity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcityblock\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_clusters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnectivity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m.\u001b[39mDBSCAN(eps\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    130\u001b[0m clustering_algorithms \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    131\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKMeans\u001b[39m\u001b[38;5;124m\"\u001b[39m, kmeans),\n\u001b[1;32m    132\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgglomerative\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClustering [Ward]\u001b[39m\u001b[38;5;124m\"\u001b[39m, ward),\n\u001b[1;32m    133\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgglomerative\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClustering [Average]\u001b[39m\u001b[38;5;124m\"\u001b[39m, average_linkage),\n\u001b[1;32m    134\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDBSCAN\u001b[39m\u001b[38;5;124m\"\u001b[39m, dbscan),\n\u001b[1;32m    135\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: AgglomerativeClustering.__init__() got an unexpected keyword argument 'affinity'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2100x1300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# ============\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "# ============\n",
    "n_samples = 500\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "# Anisotropicly distributed data\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "# blobs with varied variances\n",
    "varied = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
    "\n",
    "# ============\n",
    "# Set up cluster parameters\n",
    "# ============\n",
    "plt.figure(figsize=(9 * 2 + 3, 13))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.01\n",
    ")\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "default_base = {\n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 3,\n",
    "    \"n_clusters\": 3,\n",
    "    \"min_samples\": 7,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "}\n",
    "\n",
    "datasets = [\n",
    "    (\n",
    "        noisy_circles,\n",
    "        {\n",
    "            \"damping\": 0.77,\n",
    "            \"preference\": -240,\n",
    "            \"quantile\": 0.2,\n",
    "            \"n_clusters\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.08,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        noisy_moons,\n",
    "        {\n",
    "            \"damping\": 0.75,\n",
    "            \"preference\": -220,\n",
    "            \"n_clusters\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.1,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        varied,\n",
    "        {\n",
    "            \"eps\": 0.18,\n",
    "            \"n_neighbors\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.01,\n",
    "            \"min_cluster_size\": 0.2,\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        aniso,\n",
    "        {\n",
    "            \"eps\": 0.15,\n",
    "            \"n_neighbors\": 2,\n",
    "            \"min_samples\": 7,\n",
    "            \"xi\": 0.1,\n",
    "            \"min_cluster_size\": 0.2,\n",
    "        },\n",
    "    ),\n",
    "    (blobs, {\"min_samples\": 7, \"xi\": 0.1, \"min_cluster_size\": 0.2}),\n",
    "    (no_structure, {}),\n",
    "]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params[\"quantile\"])\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params[\"n_neighbors\"], include_self=False\n",
    "    )\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # ============\n",
    "    # Create cluster objects\n",
    "    # ============\n",
    "    kmeans = cluster.KMeans(n_clusters=params[\"n_clusters\"])\n",
    "    ward = cluster.AgglomerativeClustering(n_clusters=params[\"n_clusters\"], linkage=\"ward\", connectivity=connectivity)\n",
    "    average_linkage = cluster.AgglomerativeClustering(linkage=\"average\", affinity=\"cityblock\", n_clusters=params[\"n_clusters\"], connectivity=connectivity)\n",
    "    dbscan = cluster.DBSCAN(eps=params[\"eps\"])\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        (\"KMeans\", kmeans),\n",
    "        (\"Agglomerative\\nClustering [Ward]\", ward),\n",
    "        (\"Agglomerative\\nClustering [Average]\", average_linkage),\n",
    "        (\"DBSCAN\", dbscan),\n",
    "    )\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "        algorithm.fit(X)\n",
    "\n",
    "        if hasattr(algorithm, \"labels_\"):\n",
    "            y_pred = algorithm.labels_.astype(int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "\n",
    "        colors = np.array(\n",
    "            list(\n",
    "                islice(\n",
    "                    cycle(\n",
    "                        [\n",
    "                            \"#377eb8\",\n",
    "                            \"#ff7f00\",\n",
    "                            \"#4daf4a\",\n",
    "                            \"#f781bf\",\n",
    "                            \"#a65628\",\n",
    "                            \"#984ea3\",\n",
    "                            \"#999999\",\n",
    "                            \"#e41a1c\",\n",
    "                            \"#dede00\",\n",
    "                        ]\n",
    "                    ),\n",
    "                    int(max(y_pred) + 1),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        # add black color for outliers (if any)\n",
    "        colors = np.append(colors, [\"#000000\"])\n",
    "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "\n",
    "        plt.xlim(-2.5, 2.5)\n",
    "        plt.ylim(-2.5, 2.5)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bca97e-c038-432c-bab3-ad1232ccee75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
